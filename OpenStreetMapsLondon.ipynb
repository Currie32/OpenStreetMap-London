{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import sqlite3\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#OSM_FILE contains all the data, SAMPLE_FILE contain just a sample\n",
    "OSM_FILE = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/london_england.osm\" \n",
    "SAMPLE_FILE = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/sample_london.osm\"\n",
    "\n",
    "#This gives us 1/500 of the data for my sample\n",
    "k = 500 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    '''writes the SAMPLE_FILE from the OSM_FILE'''\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about users: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.1\n",
    "def users(filename):\n",
    "    '''Returns how many users there are from a file (filename), and how many edits each of them have.'''\n",
    "    users = {}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get('uid'):\n",
    "            id = element.attrib['uid']\n",
    "            if id not in users:\n",
    "                users[id] = 1\n",
    "            else:\n",
    "                users[id] += 1\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.2\n",
    "def total_user_edits(filename):\n",
    "    '''Counts the total number of user edits from a file(filename).'''\n",
    "    all_users = users(filename)\n",
    "    return sum(all_users.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.3\n",
    "def top_users(number_of_users, filename):\n",
    "    '''\n",
    "    Use the previous two function to determine how many users (number_of_users) \n",
    "    make what percentage of the total edits from a file.'''\n",
    "    all_users = users(filename)\n",
    "    sorted_users = sorted(all_users.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    total_edits = total_user_edits(filename)\n",
    "    i = 1\n",
    "    top_users = 0.0\n",
    "    for user in sorted_users:\n",
    "        top_users += user[1]\n",
    "        if i == number_of_users:\n",
    "            print top_users\n",
    "            print round(top_users/total_edits,4)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2.1\n",
    "'''\n",
    "\"lower\" - for tags that contain only lowercase letters and are valid; \n",
    "\"lower_colon\" - for otherwise valid tags with a colon in their names; \n",
    "\"problemchars\" - for tags with problematic characters; \n",
    "\"other\" - for other tags that do not fall into the other three categories.\n",
    "'''\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.2\n",
    "def key_type(element, keys):\n",
    "    '''Sort elements by which type of key they are, and returns the type of key.'''\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        if lower.search(k):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(k):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(k):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.3\n",
    "def count_key_type(filename):\n",
    "    '''Returns the total number of each type of key from a file.'''\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Useful Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.1\n",
    "def audit_key(filename, key):\n",
    "    '''Find all the values for a particular key and returns a dictionary of all of the unique values.'''\n",
    "    the_file = open(filename, \"r\")\n",
    "    dic = set()\n",
    "    for event, elem in ET.iterparse(the_file, events=(\"start\",)):\n",
    "        for tag in elem.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == key:\n",
    "                dic.add(tag.attrib['v'])\n",
    "    the_file.close()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.2\n",
    "def update_value(filename, key, old_v, new_v):\n",
    "    '''Replaces the old values (old_v) with new_values (new_v) from a particular key.'''\n",
    "    e = ET.parse(filename)\n",
    "    for tag in e.iter(\"tag\"):\n",
    "        if tag.attrib['k'] == key:\n",
    "            if tag.attrib['v'] == old_v:\n",
    "                tag.attrib['v'] = new_v\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the Street Types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.1\n",
    "'''A list of all of the street types I expect to find.'''\n",
    "expected_streets = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.2\n",
    "'''Compile a regular expression pattern.'''\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.3\n",
    "def audit_street_type(street_types, street_name):\n",
    "    '''Add unexpected street types into a dictionary.'''\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_streets:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.4\n",
    "def audit_streets(filename):\n",
    "    '''Finds and creates a dictionary of all the unexpected street types.'''\n",
    "    the_file = open(filename, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(the_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:street':\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    the_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4.5\n",
    "'''A dictionary of street types that need to be corrected.'''\n",
    "corrected_street_types = {\"Ave\": \"Avenue\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4.6\n",
    "def update_street_name(filename, old_v, new_v):\n",
    "    '''Replaces the old street types (old_v) with new street types (new_v) and returns the new street name.'''\n",
    "    e = ET.parse(filename)\n",
    "    for tag in e.iter(\"tag\"):\n",
    "        if tag.attrib['k'] == 'addr:street':\n",
    "            if old_v in tag.attrib['v']:\n",
    "                fix = tag.attrib['v'].split()\n",
    "                if old_v == fix[-1]:\n",
    "                    fix[-1] = new_v\n",
    "                    new_street_name = ''\n",
    "                    for word in fix:\n",
    "                        new_street_name += word + \" \"\n",
    "    return new_street_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update City Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alton',\n",
       " 'Ashford',\n",
       " 'Aylesford',\n",
       " 'Borough Green',\n",
       " 'Brentford',\n",
       " 'Burnham-On-Crouch',\n",
       " 'Chelmsford',\n",
       " 'Colchester',\n",
       " 'Crawley',\n",
       " 'Dartford',\n",
       " 'Farnham',\n",
       " 'Godalming',\n",
       " 'Hambledon',\n",
       " 'Harlow',\n",
       " 'Heybridge',\n",
       " 'High Wycombe',\n",
       " 'Horsham',\n",
       " 'Houghton Regis',\n",
       " 'LONDON',\n",
       " 'Langley',\n",
       " 'Leaden Roding, Dunmow',\n",
       " 'Leybourne',\n",
       " 'London',\n",
       " 'London Borough of Lewisham',\n",
       " 'Luton',\n",
       " 'Maldon',\n",
       " 'Mundon',\n",
       " 'Odiham',\n",
       " 'Reading',\n",
       " 'Redhill',\n",
       " 'Rochester',\n",
       " 'Royal Borough of Greenwich',\n",
       " 'Slough',\n",
       " 'Spelthorne',\n",
       " 'St Albans',\n",
       " 'St. Albans',\n",
       " 'Swanley',\n",
       " 'Tonbridge',\n",
       " 'Twickenham',\n",
       " 'Virginia Water',\n",
       " 'Walthamstow',\n",
       " 'Wembley',\n",
       " 'Woking',\n",
       " 'Wokingham'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.1\n",
    "'''Find all the city names.'''\n",
    "audit_key(SAMPLE_FILE, 'addr:city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5.2\n",
    "'''Create a dictionary to correct all the incorract city names.'''\n",
    "corrected_city_names = {'key_name': 'addr:city',\n",
    "                        'corrected_values': {\"LONDON\": \"London\",\n",
    "                                            \"St Albans\": \"St. Albans\",\n",
    "                                            \"Twickenham\": \"London\",\n",
    "                                            \"Wembley\": \"London\",\n",
    "                                            \"London Borough of Lewisham\": \"London\",\n",
    "                                            \"Royal Borough of Greenwich\": \"London\"\n",
    "                                          }\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Types of Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apartments',\n",
       " 'barn',\n",
       " 'block',\n",
       " 'bunker',\n",
       " 'church',\n",
       " 'commercial',\n",
       " 'construction',\n",
       " 'farm',\n",
       " 'flats',\n",
       " 'garage',\n",
       " 'garages',\n",
       " 'greenhouse',\n",
       " 'hotel',\n",
       " 'house',\n",
       " 'industrial',\n",
       " 'maisonette',\n",
       " 'office',\n",
       " 'outbuilding',\n",
       " 'part',\n",
       " 'residential',\n",
       " 'retail',\n",
       " 'school',\n",
       " 'school_hostel',\n",
       " 'semi',\n",
       " 'shed',\n",
       " 'shop',\n",
       " 'station',\n",
       " 'terrace',\n",
       " 'under_construction',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.1\n",
    "'''Find all the types of buildings.'''\n",
    "audit_key(SAMPLE_FILE, 'building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are no types of buildings that need to be corrected, so no further action will be taken.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.2\n",
    "'''There are no types of buildings that need to be corrected, so no further action will be taken.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Types of Amenities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atm',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bench',\n",
       " 'bicycle_parking',\n",
       " 'bicycle_rental',\n",
       " 'boat_rental',\n",
       " 'bureau_de_change',\n",
       " 'cafe',\n",
       " 'car_sharing',\n",
       " 'college',\n",
       " 'dojo',\n",
       " 'drinking_water',\n",
       " 'emergency_phone',\n",
       " 'fast_food',\n",
       " 'former_nightclub',\n",
       " 'fuel',\n",
       " 'grave_yard',\n",
       " 'grit_bin',\n",
       " 'hospital',\n",
       " 'kindergarten',\n",
       " 'motorcycle_parking',\n",
       " 'parking',\n",
       " 'parking_space',\n",
       " 'pharmacy',\n",
       " 'place_of_worship',\n",
       " 'police',\n",
       " 'post_box',\n",
       " 'post_office',\n",
       " 'pub',\n",
       " 'public_building',\n",
       " 'recycling',\n",
       " 'restaurant',\n",
       " 'school',\n",
       " 'shelter',\n",
       " 'shopping',\n",
       " 'social_facility',\n",
       " 'telephone',\n",
       " 'toilets',\n",
       " 'townhall',\n",
       " 'veterinary',\n",
       " 'waste_basket'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.1\n",
    "'''Find all the types of amenities.'''\n",
    "audit_key(SAMPLE_FILE, 'amenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are no types of amenities that need to be corrected, so no further action will be taken.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.2\n",
    "'''There are no types of amenities that need to be corrected, so no further action will be taken.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Speed Limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10 mph',\n",
       " '129',\n",
       " '20',\n",
       " '20 mph',\n",
       " '30 mph',\n",
       " '30mph',\n",
       " '40',\n",
       " '40 mph',\n",
       " '45 mph',\n",
       " '5 mph',\n",
       " '50 mph',\n",
       " '60 mph',\n",
       " '70 mph',\n",
       " '90 mph'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.1\n",
    "'''Find all the speed limits.'''\n",
    "audit_key(SAMPLE_FILE, 'maxspeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8.2\n",
    "'''Create a dictionary to correct all the incorract speed limits.'''\n",
    "corrected_speed_limits = {'key_name': 'maxspeed',\n",
    "                          'corrected_values': {'20': '20 mph',\n",
    "                                               '30mph': '30 mph',\n",
    "                                               '40': '40 mph'\n",
    "                                              }\n",
    "                         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Postal Codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AL1 1EZ',\n",
       " 'AL1 2BY',\n",
       " 'BR8 7BU',\n",
       " 'BR8 7HE',\n",
       " 'BR8 7JJ',\n",
       " 'BR8 7UB',\n",
       " 'BR8 7YF',\n",
       " 'CM1 1AQ ',\n",
       " 'CM3 3BG',\n",
       " 'CM6 1RB',\n",
       " 'CO3 3AZ',\n",
       " 'CO3 4PH',\n",
       " 'E1 6LZ',\n",
       " 'E14 3AP',\n",
       " 'E18 2AQ',\n",
       " 'E18 2DT',\n",
       " 'E18 2EN',\n",
       " 'E18 2EP',\n",
       " 'E3',\n",
       " 'E5 0EX',\n",
       " 'EC4R 3TB',\n",
       " 'EN11 0LN',\n",
       " 'EN11 0PG',\n",
       " 'EN11 9DF',\n",
       " 'EN11 9EY',\n",
       " 'EN11 9HZ',\n",
       " 'EN11 9LH',\n",
       " 'EN11 9LN',\n",
       " 'EN11 9PG',\n",
       " 'EN11 9QB',\n",
       " 'EN5 3AU',\n",
       " 'GU10 1PU',\n",
       " 'GU22 7NJ',\n",
       " 'GU22 7PX',\n",
       " 'GU23 6LJ',\n",
       " 'GU25 4PX',\n",
       " 'GU33 7DB',\n",
       " 'GU34 4QL',\n",
       " 'GU8 4EA',\n",
       " 'HA1 3LS',\n",
       " 'HA2 0AD',\n",
       " 'HA2 9AG',\n",
       " 'HA4',\n",
       " 'HP11 2AX',\n",
       " 'KT13 8UE',\n",
       " 'LU1 3NW',\n",
       " 'LU2 9QT',\n",
       " 'LU4 9SF',\n",
       " 'LU5 5PU',\n",
       " 'ME19 5QG',\n",
       " 'ME19 5QL',\n",
       " 'ME20 7BE',\n",
       " 'ME4 5UE',\n",
       " 'ME5 7HH',\n",
       " 'ME7 2HL',\n",
       " 'ME7 2LP',\n",
       " 'ME7 3BX',\n",
       " 'ME7 3DB',\n",
       " 'ME7 4HT',\n",
       " 'ME7 5QL',\n",
       " 'N1 2LL',\n",
       " 'N1 2PG',\n",
       " 'N1 6HG',\n",
       " 'N12 7LE',\n",
       " 'N19 5PZ',\n",
       " 'NW1 8AL',\n",
       " 'NW2 1LP',\n",
       " 'NW3 2AG',\n",
       " 'NW6 2NS',\n",
       " 'NW6 4NY',\n",
       " 'NW6 6AG',\n",
       " 'RG291AL',\n",
       " 'RG41 2TH',\n",
       " 'RG6 1QA',\n",
       " 'RH1 5BJ',\n",
       " 'RH10 7XF',\n",
       " 'RH11 8DD',\n",
       " 'RH12 1PP',\n",
       " 'RH13 5ED',\n",
       " 'RH13 5EY',\n",
       " 'RH13 5SJ',\n",
       " 'RH13 5SS',\n",
       " 'RH13 5TF',\n",
       " 'RH13 6DQ',\n",
       " 'RH13 6QD',\n",
       " 'RH13 9AN',\n",
       " 'RH6 7BZ',\n",
       " 'SE1 6FD',\n",
       " 'SE1 7PB',\n",
       " 'SE10 8FR',\n",
       " 'SE12 0AL',\n",
       " 'SE19 1RX',\n",
       " 'SE22 9HF',\n",
       " 'SE5 0NS',\n",
       " 'SG12 7DT',\n",
       " 'SL3 8HJ',\n",
       " 'SL4 2EU',\n",
       " 'SW11 3TS',\n",
       " 'SW11 6QE',\n",
       " 'SW20 8BW',\n",
       " 'SW4 7JQ',\n",
       " 'TN15 8RQ',\n",
       " 'TN31 7LB',\n",
       " 'TN31 7LR',\n",
       " 'TN9 1JP',\n",
       " 'TW1 3SG',\n",
       " 'TW196AQ',\n",
       " 'TW8 0NT',\n",
       " 'UB1 1RP',\n",
       " 'W13 9SH',\n",
       " 'W1U 6BA',\n",
       " 'W3 0L',\n",
       " 'W5',\n",
       " 'W9 1EE',\n",
       " 'WC1X 8PX',\n",
       " 'WC2H 9LJ'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9.1\n",
    "'''Find all the postal codes.'''\n",
    "audit_key(SAMPLE_FILE, 'addr:postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9.2\n",
    "'''Create a dictionary to correct all the incorract postal codes.'''\n",
    "corrected_postal_codes = {'key_name': 'addr:postcode',\n",
    "                          'corrected_values': {\"RG291AL\": \"RG29 1AL\",\n",
    "                                               \"TW196AQ\": \"TW19 6AQ\"\n",
    "                                              }\n",
    "                         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Auto_OS_OpenData_StreetView',\n",
       " 'Bing',\n",
       " 'Bing (2015-12-16)',\n",
       " 'Bing 2012',\n",
       " 'Bing 2012 + Local Knowledge',\n",
       " 'Bing, Survey',\n",
       " 'Bing;OS StreetView',\n",
       " 'Bing;photograph',\n",
       " 'Bing;photographic_survey',\n",
       " 'Bing;survey',\n",
       " 'DfT source data',\n",
       " 'GPS',\n",
       " 'GPS Survey',\n",
       " 'GPS track',\n",
       " 'Landsat photo',\n",
       " 'Local Knowledge',\n",
       " 'Local knowledge',\n",
       " 'London Borough of Southwark',\n",
       " 'Mapbox',\n",
       " 'NPE',\n",
       " 'NPE + GPX + Yahoo',\n",
       " 'NPE + survey',\n",
       " 'NPE; GPS',\n",
       " 'Name:Local Signboard',\n",
       " 'OS',\n",
       " 'OS OpenData StreetView',\n",
       " 'OS Opendata Streetview',\n",
       " 'OS Street View',\n",
       " 'OS Streetview',\n",
       " 'OS Streetview and Bing',\n",
       " 'OS VectorMap District',\n",
       " 'OS;survey',\n",
       " 'OS_OpenData_Boundary-Line',\n",
       " 'OS_OpenData_BoundaryLine',\n",
       " 'OS_OpenData_StreetView',\n",
       " 'OS_OpenData_StreetView;Bing;local_knowledge',\n",
       " 'OS_OpenData_Streetview',\n",
       " 'OS_OpenData_VectorDistrict',\n",
       " 'OS_OpenData_VectorMapDistrict',\n",
       " 'OS_Opendata_StreetView',\n",
       " 'OS_Opendata_StreetView auto-trace (Tom Chance)',\n",
       " 'OS_Vectormap',\n",
       " 'OS_opendata_streetview',\n",
       " 'PGS',\n",
       " 'Photo P143-0559',\n",
       " 'Photo P144-0071',\n",
       " 'SAS',\n",
       " 'SHBC SNN',\n",
       " 'Sign on gate',\n",
       " 'St Josephs RC Primary School',\n",
       " 'Surrey Air Survey',\n",
       " 'Surrey aerial',\n",
       " 'Surrey_Aerial',\n",
       " 'Survey',\n",
       " 'Survey of 2014-10-23',\n",
       " 'Survey of 2014-12-04',\n",
       " 'Survey of 2015-05-28',\n",
       " 'Survey of 2015-08-27',\n",
       " 'Survey of 2015-09-02',\n",
       " 'Trace from Yahoo arieal',\n",
       " 'WebSite',\n",
       " 'Yahoo',\n",
       " 'Yahoo - mid-construction!',\n",
       " 'Yahoo WMS',\n",
       " 'Yahoo aerial, local knowledge',\n",
       " 'Yahoo!',\n",
       " 'Yahoo!, Bing',\n",
       " 'approx location, alligned with the street',\n",
       " 'audio',\n",
       " 'auto_os_street_view',\n",
       " 'bing',\n",
       " 'bing; GPS',\n",
       " 'bing;OS_OpenData_StreetView',\n",
       " \"developer's plans\",\n",
       " 'gps',\n",
       " 'gps+mapnoter',\n",
       " 'gps: Bing',\n",
       " 'gps;Bing',\n",
       " 'gps_survey',\n",
       " 'gpx',\n",
       " 'hcps',\n",
       " 'http://www.whitmore.harrow.sch.uk/',\n",
       " 'interpolation',\n",
       " 'knowledge',\n",
       " 'landsat',\n",
       " 'local knowledge',\n",
       " 'local_knowledge',\n",
       " 'naptan_import',\n",
       " 'naptan_import;survey;Bing',\n",
       " 'npe',\n",
       " 'npe + yahoo + gpx',\n",
       " 'npemap.org.uk; OS7',\n",
       " 'osmsync:findafountain',\n",
       " 'payment:bitcoin=yes',\n",
       " 'photo',\n",
       " 'photograph',\n",
       " 'sas',\n",
       " 'sas;survey',\n",
       " 'surrey air survey',\n",
       " 'survey',\n",
       " 'survey + fhrs',\n",
       " 'survey ch',\n",
       " 'survey, bing',\n",
       " 'survey,Bing',\n",
       " 'survey/Bing aerials',\n",
       " 'survey; gps',\n",
       " 'survey;Bing',\n",
       " 'survey;Bing 2012',\n",
       " 'survey;bing',\n",
       " 'visual estimate',\n",
       " 'visual_estimate',\n",
       " 'voice',\n",
       " 'voice, npe',\n",
       " 'www.npemap.org.uk',\n",
       " 'yahoo',\n",
       " 'yahoo + gpx',\n",
       " 'yahoo imagery',\n",
       " 'yahoo satellite images'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.1\n",
    "'''Find all the sources.'''\n",
    "audit_key(SAMPLE_FILE, 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10.2\n",
    "'''Create a dictionary to correct all the incorract sources.'''\n",
    "corrected_sources = {'key_name': 'source',\n",
    "                     'corrected_values': {'Bing (2015-12-16)': 'Bing',\n",
    "                                          'Bing 2012': 'Bing',\n",
    "                                          'Local knowledge': 'Local Knowledge',\n",
    "                                          'OS Opendata Streetview': 'OS OpenData StreetView',\n",
    "                                          'OS Street View': 'OS OpenData StreetView',\n",
    "                                          'OS Streetview': 'OS OpenData StreetView',\n",
    "                                          'OS_OpenData_Boundary-Line': 'OS OpenData Boundary-Line',\n",
    "                                          'OS_OpenData_BoundaryLine': 'OS OpenData Boundary-Line',\n",
    "                                          'OS_OpenData_Streetview': 'OS OpenData StreetView',\n",
    "                                          'OS_Opendata_StreetView': 'OS OpenData StreetView',\n",
    "                                          'OS_Opendata_StreetView auto-trace (Tom Chance)': 'OS OpenData StreetView',\n",
    "                                          'OS_opendata_streetview': 'OS OpenData StreetView',\n",
    "                                          'Surrey aerial': 'Surrey Aeriel',\n",
    "                                          'Surrey_Aerial': 'Surrey Aeriel',\n",
    "                                          'Yahoo - mid-construction!': 'Yahoo',\n",
    "                                          'Yahoo!': 'Yahoo',\n",
    "                                          'auto_os_street_view': 'OS OpenData StreetView',\n",
    "                                          'knowledge': 'Local Knowledge',\n",
    "                                          'local knowledge': 'Local Knowledge',\n",
    "                                          'local_knowledge': 'Local Knowledge',\n",
    "                                          'photo': 'photograph',\n",
    "                                          'visual_estimate': 'visual estimate',\n",
    "                                          'yahoo imagery': 'Yahoo',\n",
    "                                          'yahoo satellite images': 'Yahoo',\n",
    "                                          'bing': 'Bing',\n",
    "                                          'survey, bing': 'survey; Bing',\n",
    "                                          'survey,Bing': 'survey; Bing',\n",
    "                                          'survey/Bing aerials': 'survey; Bing',\n",
    "                                          'survey;Bing': 'survey; Bing',\n",
    "                                          'survey;Bing 2012': 'survey; Bing',\n",
    "                                          'survey;bing': 'survey; Bing',\n",
    "                                          'yahoo': 'Yahoo',\n",
    "                                          'OS_OpenData_StreetView': 'OS OpenData StreetView'\n",
    "                                         }\n",
    "                    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the XML data into csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11.1\n",
    "'''Perpare the scheme and all the files that the data will be written to.'''\n",
    "import schema\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "corrected_dictionaries = [corrected_city_names,\n",
    "                          corrected_speed_limits,\n",
    "                          corrected_postal_codes,\n",
    "                          corrected_sources]\n",
    "\n",
    "key_names = ['addr:city', 'maxspeed', 'addr:postcode', 'source']\n",
    "\n",
    "OSM_PATH = SAMPLE_FILE #File to use for export\n",
    "NODES_PATH = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/nodes.csv\"\n",
    "NODE_TAGS_PATH = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/nodes_tags.csv\"\n",
    "WAYS_PATH = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/ways.csv\"\n",
    "WAY_TAGS_PATH = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/ways_tags.csv\"\n",
    "WAY_NODES_PATH = \"/Users/Dave/Desktop/Programming/Personal Projects/OpenStreetMap/ways_nodes.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11.2\n",
    "def correct_k(k):\n",
    "    index=k.find(':')\n",
    "    typ=k[:index]\n",
    "    k=k[index+1:]    \n",
    "    return k,typ\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    '''Clean and shape node or way XML element to Python dict.'''\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    if element.tag=='node':\n",
    "        for node in NODE_FIELDS:\n",
    "            try:\n",
    "                node_attribs[node] = element.attrib[node]\n",
    "            except:\n",
    "                node_attribs[node] = '0000000'\n",
    "            \n",
    "    if element.tag=='way':\n",
    "        for way in WAY_FIELDS:\n",
    "            way_attribs[way]=element.attrib[way]\n",
    "        \n",
    "    for tag in element.iter(\"tag\"):\n",
    "        dic={}\n",
    "    \n",
    "        if tag.attrib['k'] == 'addr:street':\n",
    "            value = tag.attrib['v']\n",
    "            if value.split()[-1] in corrected_street_types.keys():\n",
    "                street_type = value.split()[-1]\n",
    "                dic['value'] = update_street_name(OSM_PATH, street_type, corrected_street_types[street_type])\n",
    "                tag.attrib['v'] = dic['value']\n",
    "        \n",
    "        if tag.attrib['k'] in key_names:\n",
    "            value = tag.attrib['v']\n",
    "            for dictionary in corrected_dictionaries:\n",
    "                if value in dictionary['corrected_values']:\n",
    "                    dic['value'] = update_value(OSM_PATH, \n",
    "                                                tag.attrib['k'], \n",
    "                                                value, \n",
    "                                                dictionary['corrected_values'][value])\n",
    "                    tag.attrib['v'] = dic['value']\n",
    "        \n",
    "        if problem_chars.search(tag.attrib['k']):\n",
    "            continue\n",
    "        \n",
    "        if element.tag=='node':\n",
    "            dic['id']=node_attribs['id']\n",
    "        else:\n",
    "            dic['id']=way_attribs['id']\n",
    "        dic['value']=tag.attrib['v']\n",
    "        \n",
    "        colon_k=LOWER_COLON.search(tag.attrib['k'])\n",
    "        if colon_k:\n",
    "            dic['key'],dic['type']=correct_k(tag.attrib['k'])\n",
    "            \n",
    "        else:\n",
    "            dic['key']=tag.attrib['k']\n",
    "            dic['type']='regular'\n",
    "        \n",
    "        tags.append(dic)\n",
    "    \n",
    "    if element.tag=='way':\n",
    "        position=0\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            way_node_dic={}\n",
    "            way_node_dic['id']=way_attribs['id']\n",
    "            way_node_dic['node_id']=nd.attrib['ref']\n",
    "            way_node_dic['position']=position\n",
    "            position = position + 1\n",
    "            way_nodes.append(way_node_dic)\n",
    "        \n",
    "        \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#11.3\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    '''Yield element if it is the right type of tag.'''\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#11.4\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    '''Raise ValidationError if element does not match schema.'''\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#11.5\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    '''Extend csv.DictWriter to handle Unicode input.'''\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11.6\n",
    "def process_map(file_in, validate):\n",
    "    '''Iteratively process each XML element and write to csv(s).'''\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites used to help complete this project:\n",
    "https://www.udacity.com/\n",
    "http://stackoverflow.com/\n",
    "https://wiki.openstreetmap.org/wiki/Main_Page\n",
    "https://www.python.org/\n",
    "https://www.sqlite.org/index.html\n",
    "https://www.tutorialspoint.com/index.htm\n",
    "http://www.w3schools.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
